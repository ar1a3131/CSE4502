{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE4502: Assignment 3\n",
    "\n",
    "## NAME:[Enter your name here]\n",
    "\n",
    "\n",
    "**Due**: Tuesday, April 30, 11:59 PM\n",
    "\n",
    "**Total Points**: 100\n",
    "\n",
    "\n",
    "**How to submit**: Create a zip folder named \"Assignment3_your name\". Include the `.ipynb` file with your answers PLUS its `.html` file as a backup. \n",
    "\n",
    "**Important**: The places that require your code answer are marked with `\"# YOUR CODE\"` comments. Do not remove `\"# YOUR CODE\"`marks.\n",
    "\n",
    "\n",
    "Good Luck!\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dimensionality Reduction [20 pts]\n",
    "\n",
    "The curse of dimensionality is an issue for many applications; increasing the number of features will not always improve classification accuracy. Dimensionality reduction techniques can help with the issue. The goal is to choose an optimum set of features of lower dimensionality to improve classification accuracy. These techniques fall into two major categories: \n",
    "<br> **Feature selection:** chooses a subset of the original features\n",
    "<br> **Feature extraction:** finds a set of new features (i.e., through some mapping f()) from the existing features\n",
    "\n",
    "<br> **Principle Component Analysis (PCA)** is a feature extraction technique that can be used to both compression (reduce the memory needed to store the data, speed up learning algorithm) and visualization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **PCA in a pipeline**\n",
    "Run the following codes. Does adding PCA to the pipeline reduce overfitting in this dataset? Explain. **[Your Answer]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('Wine.csv')\n",
    "X = dataset.drop('Wine', axis =1)\n",
    "y = dataset['Wine']\n",
    "dataset.head()\n",
    "\n",
    "print('Dimensions: %s x %s' % (X.shape[0], X.shape[1]))\n",
    "print('\\nHeader: %s' % ['alcohol', 'malic acid', 'ash', 'ash alcalinity',\n",
    "                        'magnesium', 'total phenols', 'flavanoids',\n",
    "                        'nonflavanoid phenols', 'proanthocyanins',\n",
    "                        'color intensity', 'hue', 'OD280/OD315 of diluted wines',\n",
    "                        'proline'])\n",
    "\n",
    "print('\\nClasses: %s' % np.unique(y))\n",
    "print('Class distribution: %s' % np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.3, stratify=y)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Orig. training accuracy: %.2f%%' % (pipe.score(X_train, y_train)*100))\n",
    "print('Orig. test accuracy: %.2f%%' % (pipe.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_pca = make_pipeline(StandardScaler(),\n",
    "                         PCA(n_components=3),\n",
    "                         KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "pipe_pca.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Transf. training accuracy: %.2f%%' % (pipe_pca.score(X_train, y_train)*100))\n",
    "print('Transf. test accuracy: %.2f%%' % (pipe_pca.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Random Forests [30 pts]\n",
    "One of the random forests output is **feature importance**. It gives you a notion of how much each feature contributes to the decision. You can use the feature importance information to (1) interpret your model and get more insight, or (2) you can use it as a feature selection method. How? Re-run your model with a subset of features that pass a certain threshold.\n",
    "\n",
    "<br> 1) Run the code. Based on the plot, which feature is the most important one? **[Your Answer]**\n",
    "<br> 2) Set the feature selection's threshold equal to '1.25\\*median' in line 4 (a parameter of SelectFromModel). How many features will be selected? **[Your Answer]**\n",
    "<br> 3) Does the performance improve using the reduced set of features? **[Your Answer]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100,random_state=123)) # YOUR CODE\n",
    "\n",
    "embeded_rf_selector.fit(X, y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support() # Get a mask, or integer index, of the features selected\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')\n",
    "print(embeded_rf_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = embeded_rf_selector.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, random_state=123, test_size=0.3, stratify=y)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Orig. training accuracy: %.2f%%' % (pipe.score(X_train, y_train)*100))\n",
    "print('Orig. test accuracy: %.2f%%' % (pipe.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(embeded_rf_selector.estimator_.feature_importances_, index=X.columns)\n",
    "print(feature_importances)\n",
    "feature_importances.sort_values(inplace=True)\n",
    "feature_importances.plot(kind='barh', figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model Evaluation [50 pts]\n",
    "\n",
    "Run the cells in this section and answer the following questions: **[Your Answers]**\n",
    "\n",
    "---\n",
    "\n",
    "1- How much will the CV accuracy change if you do not scale the data before modeling? \n",
    "\n",
    "2- What are the difference between the learning curve and the validation curve? \n",
    "\n",
    "3- Can we diagnose model overfitting/underfitting using the curves? How? \n",
    "\n",
    "4- How do we treat the overfitting/underfitting? \n",
    "\n",
    "5- Change the scoring metric in grid search from `accuracy` to `f1` and report the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                 'machine-learning-databases'\n",
    "                 '/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the class lables from string format to integers \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)\n",
    "print(le.transform(['M', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% training data and 20% test data, using a stratified split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "pipe_knn = make_pipeline(StandardScaler(),\n",
    "                        KNeighborsClassifier(n_neighbors=10))\n",
    "\n",
    "pipe_knn.fit(X_train, y_train)\n",
    "y_pred = pipe_knn.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using k-fold cross validation to assess model performance\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_knn,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores =\\\n",
    "                learning_curve(estimator=pipe_knn,\n",
    "                               X=X_train,\n",
    "                               y=y_train,\n",
    "                               train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                               cv=10,\n",
    "                               n_jobs=1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='darkorange', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='darkorange')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='navy', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='navy')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "param_range = [3, 5, 7, 9, 15, 20, 30]\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator=pipe_knn, \n",
    "                X=X_train, \n",
    "                y=y_train, \n",
    "                param_name='kneighborsclassifier__n_neighbors', \n",
    "                param_range=param_range,\n",
    "                cv=10)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "         color='darkorange', marker='o', \n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='darkorange')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "         color='navy', linestyle='--', \n",
    "         marker='s', markersize=5, \n",
    "         label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std, \n",
    "                 alpha=0.15, color='navy')\n",
    "\n",
    "plt.grid()\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning via grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_range = [3, 5, 7, 9, 15, 20, 30]\n",
    "\n",
    "pipe_knn = make_pipeline(StandardScaler(),\n",
    "                         KNeighborsClassifier())\n",
    "\n",
    "param_grid = [{'kneighborsclassifier__n_neighbors': param_range}]\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_knn,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "print('Test accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
